{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "358d46b6480881db",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" \n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import importlib\n",
    "from matplotlib import pyplot as plt\n",
    "import preprocess\n",
    "# import preprocess as prep\n",
    "\n",
    "# import SLR_model\n",
    "import SLR_model_CNN_GRU\n",
    "# import SLR_model_CL_GRU\n",
    "import numpy as np\n",
    "# from preprocess import person\n",
    "\n",
    "\n",
    "\n",
    "# model will output multiple(5) results/sec, how are we gonna handle it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc8634f5da68e224",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "load_size = 3000 # number of data to be loaded at once\n",
    "epochs = 30\n",
    "run_time=3\n",
    "batch_size = 16\n",
    "save_dir = \"saves_CNN_GRU\"\n",
    "load_dir = \"saves_CNN_GRU\"\n",
    "model = SLR_model_CNN_GRU.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9501d29fe7faee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand input shape: (batch, time, h, w, channels)\n",
    "# pose input shape: (batch, time, channel, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2da41c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timecallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        # use this value as reference to calculate cummulative time taken\n",
    "        self.timetaken = time.process_time()\n",
    "    def on_epoch_end(self,epoch,logs = {}):\n",
    "        \n",
    "        self.times.append((epoch,time.process_time() - self.timetaken))\n",
    "        print(time.process_time() - self.timetaken)\n",
    "        self.timetaken = time.process_time()\n",
    "    def on_train_end(self,logs = {}):\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Total time taken until an epoch in seconds')\n",
    "        plt.plot(*zip(*self.times))\n",
    "        plt.show()\n",
    "        \n",
    "timetaken = timecallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4e9db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cngru_model = SLR_model_CNN_GRU.reinit_model(run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aeb818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - categorical_accuracy: 0.0000e+00 - loss: 8.0687\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling SLRModel.call().\n\n\u001b[1m'NoneType' object cannot be interpreted as an integer\u001b[0m\n\nArguments received by SLRModel.call():\n  • inputs=('tf.Tensor(shape=(1, None, 17, 4, 5, 3), dtype=float32)', 'tf.Tensor(shape=(1, None, 17, 4, 5, 3), dtype=float32)', 'tf.Tensor(shape=(1, None, 5, 10, 3), dtype=float32)')\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 54\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# hist = cngru_model.fit(dataset, epochs=30)\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chkpt_elapsed \u001b[38;5;241m<\u001b[39m load_size \u001b[38;5;129;01mand\u001b[39;00m j \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# train without checkpoint\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mcngru_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     chkpt_elapsed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# train with checkpoint every {load_size}th video\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shd\\anaconda3\\envs\\BomNae-SLR\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mf:\\home\\shd\\BomNae-SLR\\SLR_model_CNN_GRU.py:345\u001b[0m, in \u001b[0;36mSLRModel.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# input shape: (batch(1) , window_count, window_size, features**)\u001b[39;00m\n\u001b[0;32m    344\u001b[0m per_window \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 345\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ml_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;66;03m# ASSUMING LRP HAS THE SAME WINDOW COUNTS\u001b[39;00m\n\u001b[0;32m    347\u001b[0m     l_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_hand_model(l_inputs[:,i], training \u001b[38;5;241m=\u001b[39m training)\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;66;03m# print(\"lh\")\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling SLRModel.call().\n\n\u001b[1m'NoneType' object cannot be interpreted as an integer\u001b[0m\n\nArguments received by SLRModel.call():\n  • inputs=('tf.Tensor(shape=(1, None, 17, 4, 5, 3), dtype=float32)', 'tf.Tensor(shape=(1, None, 17, 4, 5, 3), dtype=float32)', 'tf.Tensor(shape=(1, None, 5, 10, 3), dtype=float32)')\n  • training=True"
     ]
    }
   ],
   "source": [
    "# PER VIDEO TRAINING LOOP\n",
    "\n",
    "end_file=preprocess.getoutputdir()\n",
    "\n",
    "save_suffix = time.strftime(\"%m-%d-%H\", time.localtime(time.time()))\n",
    "ckpt_name=save_suffix+\"-\"+str(epochs)+\"epochs-\"+str(run_time)+\"times\"\n",
    "\n",
    "check_path = os.path.join(save_dir,'ckpt',ckpt_name)\n",
    "hist_path = os.path.join(save_dir, \"hist\",ckpt_name+\".json\")\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "filepath=f'{check_path}.keras',\n",
    "monitor='categorical_accuracy',\n",
    "mode='max',\n",
    "save_freq='epoch',\n",
    "save_best_only=True)\n",
    "\n",
    "\n",
    "start_person=1\n",
    "\n",
    "for i in range(1,17):\n",
    "    if start_person>i:\n",
    "        continue\n",
    "    for k in range(1,run_time+1):\n",
    "        chkpt_elapsed = 0\n",
    "        file_list = sorted(os.listdir(os.path.join(preprocess.getoutputdir(),str(i))))\n",
    "        for j in file_list: # every video\n",
    "            l_raw, r_raw, p_raw, y_raw, loss_weights_raw = preprocess.load_data(f\"{i}/{j}\")\n",
    "            with open(os.path.join('logs',ckpt_name+'.txt'), 'a') as logs:\n",
    "                hist = None # declaration for scope\n",
    "                logs.write(f'{ time.strftime(\"%H-%M-%S\", time.localtime(time.time()))}:{k}) person:{i} : {j}\\n')  # 한 줄 쓰기\n",
    "                ## ----------------------------------------------------\n",
    "                ## CLGRU <-> CNNGRU 전환시 serialize 인자값 바꿔줄 것\n",
    "                ## --------------------------------------\n",
    "                # PER VIDEO TRAINING LOOP\n",
    "                l_train, window_count = SLR_model_CNN_GRU.serialize(l_raw, stride=1, window_size=17, hop_length=10)\n",
    "                r_train, window_count = SLR_model_CNN_GRU.serialize(r_raw, stride=1, window_size=17, hop_length=10)\n",
    "                p_train, window_count, sample_weights = SLR_model_CNN_GRU.serialize(p_raw, stride=2, window_size=9, hop_length=6, loss_weights=loss_weights_raw, is_pose=True)\n",
    "                x_train = (l_train, r_train, p_train)\n",
    "\n",
    "                y_train = np.repeat(y_raw, window_count)\n",
    "                y_train = SLR_model_CNN_GRU.encode_onehot2d(y_raw)\n",
    "                y_train = tf.expand_dims(y_train, axis=0)\n",
    "                # print(y_train.shape)\n",
    "                # print(\"li:\",x_train[0].shape)\n",
    "                # print(\"ri:\",x_train[1].shape)\n",
    "                # print(x_train[2].shape)\n",
    "                # print(sample_weights.shape)\n",
    "                dataset = SLR_model_CNN_GRU.convert_to_dataset(x_train, y_train, batch_size= 1)#, sample_weights= sample_weights)\n",
    "                # hist = cngru_model.fit(dataset, epochs=30)\n",
    "                                \n",
    "                if chkpt_elapsed < load_size and j is not file_list[-1]:\n",
    "                    # train without checkpoint\n",
    "                    print(cngru_model.summary())\n",
    "                    hist = cngru_model.fit(dataset, epochs=1)\n",
    "                    chkpt_elapsed += 1\n",
    "                else:\n",
    "                    # train with checkpoint every {load_size}th video\n",
    "                    hist = cngru_model.fit(dataset, epochs=epochs, callbacks=[model_checkpoint_callback])\n",
    "                    chkpt_elapsed = 0   \n",
    "\n",
    "                with open(hist_path, 'w') as file:\n",
    "                    json.dump(hist.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5961b31976929d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:59:17.134279Z",
     "start_time": "2024-11-06T11:59:17.102279Z"
    }
   },
   "outputs": [],
   "source": [
    "# LEGACY TRAINING LOOP WITH LOAD SIZE  \n",
    "\n",
    " # reload model file\n",
    "end_file=preprocess.getoutputdir()\n",
    "\n",
    "save_suffix = time.strftime(\"%m-%d-%H\", time.localtime(time.time()))\n",
    "ckpt_name=save_suffix+\"-\"+str(epochs)+\"epochs-\"+str(run_time)+\"times\"\n",
    "\n",
    "check_path = os.path.join(save_dir,'ckpt',ckpt_name)\n",
    "hist_path = os.path.join(save_dir, \"hist\",ckpt_name+\".json\")\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "filepath=f'{check_path}.keras',\n",
    "monitor='categorical_accuracy',\n",
    "mode='max',\n",
    "save_freq='epoch',\n",
    "save_best_only=True)\n",
    "\n",
    "\n",
    "start_person=1\n",
    "start_count=1\n",
    "current_word=\" \"\n",
    "\n",
    "for i in range(1,17):\n",
    "    l_raws=[]\n",
    "    r_raws=[]\n",
    "    p_raws=[]\n",
    "    y_raws=[]\n",
    "    loss_weights_raws=[]\n",
    "    if start_person>i:\n",
    "        continue\n",
    "    for k in range(1,run_time+1):\n",
    "        if start_count>k:\n",
    "            continue\n",
    "        elif start_count==k:\n",
    "            start_count=0\n",
    "        for j in sorted(os.listdir(os.path.join(preprocess.getoutputdir(),str(i)))):\n",
    "            if len(l_raws)==0:\n",
    "                current_word = j\n",
    "            else:\n",
    "                end_word = j\n",
    "            l_raw, r_raw, p_raw, y_raw, loss_weights_raw = preprocess.load_data(f\"{i}/{j}\")\n",
    "            l_raws.append(l_raw)\n",
    "            r_raws.append(r_raw)\n",
    "            p_raws.append(p_raw)\n",
    "            y_raws.append(y_raw)\n",
    "            loss_weights_raws.append(loss_weights_raw)\n",
    "            # print(p_raw.shape)\n",
    "            # break\n",
    "            if len(l_raws)>=load_size:\n",
    "                with open(os.path.join('logs',ckpt_name+'.txt'), 'a') as logs:\n",
    "                    logs.write(f'{ time.strftime(\"%H-%M-%S\", time.localtime(time.time()))}:{k}) person:{i} : {current_word} ~ {end_word}\\n')  # 한 줄 쓰기\n",
    "                    l_train, each = SLR_model_GRU.serialize(l_raws)\n",
    "                    r_train, each = SLR_model_GRU.serialize(r_raws)\n",
    "                    p_train, each, sample_weights = SLR_model_GRU.serialize(p_raws, stride=2, loss_weights_list=loss_weights_raws)\n",
    "                    x_train = (l_train, r_train, p_train)\n",
    "                    \n",
    "                    y_train = np.repeat(y_raws, each)\n",
    "                    y_train = SLR_model_GRU.encode_onehot2d(y_train)\n",
    "                    \n",
    "                    dataset = SLR_model_GRU.convert_to_dataset(x_train, y_train, batch_size, sample_weights)\n",
    "                    hist = model.fit(dataset, epochs=epochs, callbacks=[model_checkpoint_callback])\n",
    "\n",
    "                    with open(hist_path, 'w') as file:\n",
    "                        json.dump(hist.history, file)\n",
    "                    l_raws.clear()\n",
    "                    r_raws.clear()\n",
    "                    p_raws.clear()\n",
    "                    y_raws.clear()\n",
    "                    loss_weights_raws.clear()\n",
    "            if len(l_raws)>0:\n",
    "                l_train, each = SLR_model_GRU.serialize(l_raws)\n",
    "                r_train, each = SLR_model_GRU.serialize(r_raws)\n",
    "                p_train, each, sample_weights = SLR_model_GRU.serialize(p_raws, stride=2, loss_weights_list=loss_weights_raws)\n",
    "                x_train = (l_train, r_train, p_train)\n",
    "                \n",
    "                y_train = np.repeat(y_raws, each)\n",
    "                y_train = SLR_model_GRU.encode_onehot2d(y_train)\n",
    "                \n",
    "                \n",
    "                dataset = SLR_model_GRU.convert_to_dataset(x_train, y_train, batch_size, sample_weights)\n",
    "                hist = model.fit(dataset, epochs=epochs, callbacks=[model_checkpoint_callback])\n",
    "\n",
    "                with open(hist_path, 'w') as file:\n",
    "                    json.dump(hist.history, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217de3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e74e08d3b98fea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:59:17.273289Z",
     "start_time": "2024-11-06T11:59:17.262280Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configurations\n",
    "load_size = 3000 # number of data to be loaded at once\n",
    "epochs = 50\n",
    "run_time = 2\n",
    "batch_size = 16\n",
    "save_dir = \"saves\"\n",
    "load_dir = \"saves\"\n",
    "# load_path = \"C:/Users/jerry/Desktop/hly/2024-2/cap/BN_SLR/BomNae-SLR/checkpoints.keras\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589a3ca3f4b1820c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:59:17.382288Z",
     "start_time": "2024-11-06T11:59:17.372290Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SLR_model.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96948ee065658f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 세이브된 모델 로드\n",
    "# load_path = os.join(load_dir, \"check_00-00-00.keras\")\n",
    "# model = SLR_model.load_model(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac698d86f47869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 안될때 (강제중지 + 초기화)\n",
    "# tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bad08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"saves_GRU\",\"hist\",\"11-06-21-50epochs-2times.json\"), 'r') as f:\n",
    "    hist = json.load(f)\n",
    "\n",
    "    plt.plot(range(len(hist['loss'])), hist['loss'])\n",
    "    plt.scatter(range(len(hist['loss'])), hist['loss'])\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend([\"loss\"])\n",
    "    plt.ylim((0,1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981331a75aa7e19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:02:15.876445Z",
     "start_time": "2024-10-14T14:02:15.873228Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(os.listdir(os.path.join(preprocess.getoutputdir(),str(15))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.metrics_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BomNae-SLR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
