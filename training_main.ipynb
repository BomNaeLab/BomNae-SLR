{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "358d46b6480881db",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" \n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import importlib\n",
    "from matplotlib import pyplot as plt\n",
    "import preprocess_lite\n",
    "# import preprocess as prep\n",
    "\n",
    "import SLR_model \n",
    "import SLR_model_CNN_GRU\n",
    "# import SLR_model_CL_GRU\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# model will output multiple(5) results/sec, how are we gonna handle it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc8634f5da68e224",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "load_size = 1500 # number of data to be loaded at once\n",
    "epochs = 30\n",
    "run_time= 5\n",
    "batch_size = 8\n",
    "save_dir = \"saves\"\n",
    "load_dir = \"saves\"\n",
    "model = SLR_model.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9501d29fe7faee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand input shape: (batch, time, h, w, channels)\n",
    "# pose input shape: (batch, time, channel, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa2c146-2659-4242-baf7-c2c608b182a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16-28-21:1) person:1 : 0001.npz ~ 1592.npz\n",
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732087703.997893  757128 service.cc:146] XLA service 0x7e8d2801a3c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732087703.997916  757128 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti, Compute Capability 8.9\n",
      "2024-11-20 16:28:24.043162: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-20 16:28:24.242229: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  18/2010\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - categorical_accuracy: 0.1097 - loss: 6.0635  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732087707.210265  757128 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 10ms/step - categorical_accuracy: 0.0033 - loss: 5.1102\n",
      "Epoch 2/30\n",
      "\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - categorical_accuracy: 7.7954e-04 - loss: 4.8829\n",
      "Epoch 3/30\n",
      "\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - categorical_accuracy: 6.8896e-04 - loss: 4.8555\n",
      "Epoch 4/30\n",
      "\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - categorical_accuracy: 0.0028 - loss: 4.8127\n",
      "Epoch 5/30\n",
      "\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - categorical_accuracy: 0.0045 - loss: 4.7944\n",
      "Epoch 6/30\n",
      "\u001b[1m1927/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - categorical_accuracy: 0.0063 - loss: 4.7429"
     ]
    }
   ],
   "source": [
    "end_file=preprocess_lite.getoutputdir()\n",
    "\n",
    "save_suffix = time.strftime(\"%m-%d-%H\", time.localtime(time.time()))\n",
    "ckpt_name=save_suffix+\"-\"+str(epochs)+\"epochs-\"+str(run_time)+\"times\"+\"_final\"\n",
    "\n",
    "check_path = os.path.join(save_dir,'ckpt',ckpt_name)\n",
    "hist_path = os.path.join(save_dir, \"hist\",ckpt_name+\".json\")\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "filepath=f'{check_path}.keras',\n",
    "monitor='categorical_accuracy',\n",
    "mode='max',\n",
    "save_freq='epoch',\n",
    "save_best_only=True)\n",
    "\n",
    "\n",
    "start_person=1\n",
    "start_count=1\n",
    "current_word=\" \"\n",
    "for i in sorted(os.listdir(preprocess_lite.getoutputdir())):\n",
    "    l_raws, r_raws, p_raws, y_raws, loss_weights_raws = [], [], [], [], []\n",
    "    if 2 == int(i):\n",
    "        continue\n",
    "\n",
    "    video_list = sorted(os.listdir(os.path.join(preprocess_lite.getoutputdir(), i)))\n",
    "    \n",
    "    batch_start_index = 0\n",
    "\n",
    "    for k in range(1, run_time + 1):\n",
    "        if start_count > k:\n",
    "            continue\n",
    "        elif start_count == k:\n",
    "            start_count = 0\n",
    "\n",
    "        for j_idx, j in enumerate(video_list):\n",
    "            if len(j)!=8:\n",
    "                continue\n",
    "            if len(l_raws) == 0:\n",
    "                current_word = j  # 배치 시작 단어 설정\n",
    "\n",
    "            # 데이터 로드\n",
    "            l_raw, r_raw, p_raw, y_raw, loss_weights_raw = preprocess_lite.load_data(f\"{i}/{j}\")\n",
    "            l_raws.append(l_raw)\n",
    "            r_raws.append(r_raw)\n",
    "            p_raws.append(p_raw)\n",
    "            y_raws.append(y_raw)\n",
    "            loss_weights_raws.append(loss_weights_raw)\n",
    "\n",
    "            # 배치 처리\n",
    "            if len(l_raws) >= load_size or j_idx == len(video_list) - 1:  # 배치 크기 도달 또는 마지막 파일\n",
    "                end_word = j  # 배치 마지막 단어 설정\n",
    "\n",
    "                # 로그 작성\n",
    "                with open(os.path.join('logs', f\"{ckpt_name}.txt\"), 'a') as logs:\n",
    "                    logmsg=f'{time.strftime(\"%H-%M-%S\", time.localtime(time.time()))}:{k}) person:{i} : {current_word} ~ {end_word}\\n'\n",
    "                    logs.write(logmsg)\n",
    "                    print(logmsg)\n",
    "                # 데이터 직렬화 및 모델 학습\n",
    "                l_train, window_count = SLR_model.serialize(l_raws)\n",
    "                r_train, window_count = SLR_model.serialize(r_raws)\n",
    "                p_train, window_count, sample_weights = SLR_model.serialize(\n",
    "                    p_raws, stride=2, loss_weights_list=loss_weights_raws, is_pose=True\n",
    "                )\n",
    "                x_train = (l_train, r_train, p_train)\n",
    "                y_train = np.repeat(y_raws, window_count)\n",
    "                y_train = SLR_model.encode_onehot2d(y_train)\n",
    "                dataset = SLR_model.convert_to_dataset(x_train, y_train, batch_size, sample_weights)\n",
    "\n",
    "                hist = model.fit(dataset, epochs=epochs, callbacks=[model_checkpoint_callback])\n",
    "                # 학습 기록 저장\n",
    "                with open(hist_path, 'w') as file:\n",
    "                    json.dump(hist.history, file)\n",
    "\n",
    "                # 데이터 초기화\n",
    "                l_raws.clear()\n",
    "                r_raws.clear()\n",
    "                p_raws.clear()\n",
    "                y_raws.clear()\n",
    "                loss_weights_raws.clear()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5961b31976929d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:59:17.134279Z",
     "start_time": "2024-11-06T11:59:17.102279Z"
    }
   },
   "outputs": [],
   "source": [
    "# LEGACY TRAINING LOOP WITH LOAD SIZE  \n",
    "\n",
    "#  # reload model file\n",
    "# end_file=preprocess.getoutputdir()\n",
    "\n",
    "# save_suffix = time.strftime(\"%m-%d-%H\", time.localtime(time.time()))\n",
    "# ckpt_name=save_suffix+\"-\"+str(epochs)+\"epochs-\"+str(run_time)+\"times\"\n",
    "\n",
    "# check_path = os.path.join(save_dir,'ckpt',ckpt_name)\n",
    "# hist_path = os.path.join(save_dir, \"hist\",ckpt_name+\".json\")\n",
    "\n",
    "# model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "# filepath=f'{check_path}.keras',\n",
    "# monitor='categorical_accuracy',\n",
    "# mode='max',\n",
    "# save_freq='epoch',\n",
    "# save_best_only=True)\n",
    "\n",
    "\n",
    "# start_person=1\n",
    "# start_count=1\n",
    "# current_word=\" \"\n",
    "\n",
    "# for i in range(1,17):\n",
    "#     l_raws=[]\n",
    "#     r_raws=[]\n",
    "#     p_raws=[]\n",
    "#     y_raws=[]\n",
    "#     loss_weights_raws=[]\n",
    "#     if start_person>i:\n",
    "#         continue\n",
    "#     for k in range(1,run_time+1):\n",
    "#         if start_count>k:\n",
    "#             continue\n",
    "#         elif start_count==k:\n",
    "#             start_count=0\n",
    "#         for j in sorted(os.listdir(os.path.join(preprocess.getoutputdir(),str(i)))):\n",
    "#             if len(l_raws)==0:\n",
    "#                 current_word = j\n",
    "#             else:\n",
    "#                 end_word = j\n",
    "#             l_raw, r_raw, p_raw, y_raw, loss_weights_raw = preprocess.load_data(f\"{i}/{j}\")\n",
    "#             l_raws.append(l_raw)\n",
    "#             r_raws.append(r_raw)\n",
    "#             p_raws.append(p_raw)\n",
    "#             y_raws.append(y_raw)\n",
    "#             loss_weights_raws.append(loss_weights_raw)\n",
    "#             # print(p_raw.shape)\n",
    "#             # break\n",
    "#             if len(l_raws)>=load_size:\n",
    "#                 with open(os.path.join('logs',ckpt_name+'.txt'), 'a') as logs:\n",
    "#                     logs.write(f'{ time.strftime(\"%H-%M-%S\", time.localtime(time.time()))}:{k}) person:{i} : {current_word} ~ {end_word}\\n')  # 한 줄 쓰기\n",
    "#                     l_train, window_count = SLR_model.serialize(l_raws)\n",
    "#                     r_train, window_count = SLR_model.serialize(r_raws)\n",
    "#                     p_train, window_count, sample_weights = SLR_model.serialize(p_raws, stride=2, loss_weights_list=loss_weights_raws, is_pose = True)\n",
    "#                     x_train = (l_train, r_train, p_train)\n",
    "                    \n",
    "#                     y_train = np.repeat(y_raws, window_count)\n",
    "#                     y_train = SLR_model.encode_onehot2d(y_train)\n",
    "                    \n",
    "#                     dataset = SLR_model.convert_to_dataset(x_train, y_train, batch_size, sample_weights)\n",
    "#                     hist = model.fit(dataset, epochs=epochs, callbacks=[model_checkpoint_callback])\n",
    "\n",
    "#                     with open(hist_path, 'w') as file:\n",
    "#                         json.dump(hist.history, file)\n",
    "#                     l_raws.clear()\n",
    "#                     r_raws.clear()\n",
    "#                     p_raws.clear()\n",
    "#                     y_raws.clear()\n",
    "#                     loss_weights_raws.clear()\n",
    "#             if len(l_raws)>0:\n",
    "#                 l_train, window_count = SLR_model.serialize(l_raws)\n",
    "#                 r_train, window_count = SLR_model.serialize(r_raws)\n",
    "#                 p_train, window_count, sample_weights = SLR_model.serialize(p_raws, stride=2, loss_weights_list=loss_weights_raws, is_pose = True)\n",
    "#                 x_train = (l_train, r_train, p_train)\n",
    "                \n",
    "#                 y_train = np.repeat(y_raws, window_count)\n",
    "#                 y_train = SLR_model.encode_onehot2d(y_train)\n",
    "                \n",
    "                \n",
    "#                 dataset = SLR_model.convert_to_dataset(x_train, y_train, batch_size, sample_weights)\n",
    "#                 hist = model.fit(dataset, epochs=epochs, callbacks=[model_checkpoint_callback])\n",
    "\n",
    "#                 with open(hist_path, 'w') as file:\n",
    "#                     json.dump(hist.history, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886aede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(SLR_model_CNN_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e9db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cngru_model = SLR_model_CNN_GRU.reinit_model(run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aeb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PER VIDEO TRAINING LOOP\n",
    "\n",
    "# end_file=preprocess.getoutputdir()\n",
    "\n",
    "# save_suffix = time.strftime(\"%m-%d-%H\", time.localtime(time.time()))\n",
    "# ckpt_name=save_suffix+\"-\"+str(epochs)+\"epochs-\"+str(run_time)+\"times\"\n",
    "\n",
    "# check_path = os.path.join(save_dir,'ckpt',ckpt_name)\n",
    "# hist_path = os.path.join(save_dir, \"hist\",ckpt_name+\".json\")\n",
    "\n",
    "# model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "# filepath=f'{check_path}.keras',\n",
    "# monitor='categorical_accuracy',\n",
    "# mode='max',\n",
    "# save_freq='epoch',\n",
    "# save_best_only=True)\n",
    "\n",
    "\n",
    "# start_person=1\n",
    "\n",
    "# for i in range(1,17):\n",
    "#     if start_person>i:\n",
    "#         continue\n",
    "#     for k in range(1,run_time+1):\n",
    "#         chkpt_elapsed = 0\n",
    "#         file_list = sorted(os.listdir(os.path.join(preprocess.getoutputdir(),str(i))))\n",
    "#         for j in file_list: # every video\n",
    "#             print(j)\n",
    "#             l_raw, r_raw, p_raw, y_raw, loss_weights_raw = preprocess.load_data(f\"{i}/{j}\")\n",
    "#             with open(os.path.join('logs',ckpt_name+'.txt'), 'a') as logs:\n",
    "#                 hist = None # declaration for scope\n",
    "#                 logs.write(f'{ time.strftime(\"%H-%M-%S\", time.localtime(time.time()))}:{k}) person:{i} : {j}\\n')  # 한 줄 쓰기\n",
    "#                 ## ----------------------------------------------------\n",
    "#                 ## CLGRU <-> CNNGRU 전환시 serialize 인자값 바꿔줄 것\n",
    "#                 ## --------------------------------------\n",
    "#                 # PER VIDEO TRAINING LOOP\n",
    "#                 l_train, window_count = SLR_model_CNN_GRU.serialize(l_raw, stride=1, window_size=17, hop_length=10)\n",
    "#                 r_train, window_count = SLR_model_CNN_GRU.serialize(r_raw, stride=1, window_size=17, hop_length=10)\n",
    "#                 p_train, window_count, sample_weights = SLR_model_CNN_GRU.serialize(p_raw, stride=2, window_size=17, hop_length=10, loss_weights=loss_weights_raw, is_pose=True)\n",
    "#                 x_train = (l_train, r_train, p_train)\n",
    "\n",
    "#                 # y_train = np.repeat(y_raw, window_count)\n",
    "#                 # print(y_raw.shape)\n",
    "#                 y_train = SLR_model_CNN_GRU.encode_onehot2d(y_raw)\n",
    "#                 y_train = tf.expand_dims(y_train, axis=0)\n",
    "#                 # print('yt:', y_train.shape)\n",
    "#                 # print(\"li:\",x_train[0].shape)\n",
    "#                 # print(\"ri:\",x_train[1].shape)\n",
    "#                 # print(x_train[2].shape)\n",
    "#                 # print(sample_weights.shape)\n",
    "#                 # dataset = SLR_model_CNN_GRU.convert_to_dataset(x_train, y_train, batch_size= 1)#, sample_weights= sample_weights)\n",
    "#                 # hist = cngru_model.fit(x_train, y_train, batch_size=1, epochs=epochs)\n",
    "                                \n",
    "#                 if chkpt_elapsed < load_size and j is not file_list[-1]:\n",
    "#                     # train without checkpoint\n",
    "#                     # print(cngru_model.summary())\n",
    "#                     hist = cngru_model.fit(x_train, y_train, batch_size=1, epochs=epochs)\n",
    "#                     chkpt_elapsed += 1\n",
    "#                 else:\n",
    "#                     # train with checkpoint every {load_size}th video\n",
    "#                     hist = cngru_model.fit(x_train, y_train, batch_size=1, epochs=epochs, callbacks=[model_checkpoint_callback])\n",
    "#                     chkpt_elapsed = 0   \n",
    "\n",
    "#                 with open(hist_path, 'w') as file:\n",
    "#                     json.dump(hist.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217de3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e74e08d3b98fea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:59:17.273289Z",
     "start_time": "2024-11-06T11:59:17.262280Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Configurations\n",
    "# load_size = 3000 # number of data to be loaded at once\n",
    "# epochs = 50\n",
    "# run_time = 2\n",
    "# batch_size = 16\n",
    "# save_dir = \"saves\"\n",
    "# load_dir = \"saves\"\n",
    "# # load_path = \"C:/Users/jerry/Desktop/hly/2024-2/cap/BN_SLR/BomNae-SLR/checkpoints.keras\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589a3ca3f4b1820c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:59:17.382288Z",
     "start_time": "2024-11-06T11:59:17.372290Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = SLR_model.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96948ee065658f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 세이브된 모델 로드\n",
    "# load_path = os.join(load_dir, \"check_00-00-00.keras\")\n",
    "# model = SLR_model.load_model(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac698d86f47869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 안될때 (강제중지 + 초기화)\n",
    "# tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bad08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(\"saves\",\"hist\",\"11-17-21-20epochs-3times.json\"), 'r') as f:\n",
    "#     hist = json.load(f)\n",
    "\n",
    "#     plt.plot(range(len(hist['loss'])), hist['loss'])\n",
    "#     plt.scatter(range(len(hist['loss'])), hist['loss'])\n",
    "#     plt.xlabel(\"epochs\")\n",
    "#     plt.ylabel(\"loss\")\n",
    "#     plt.legend([\"loss\"])\n",
    "#     plt.ylim((0,1))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981331a75aa7e19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:02:15.876445Z",
     "start_time": "2024-10-14T14:02:15.873228Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(os.listdir(os.path.join(preprocess.getoutputdir(),str(15))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.metrics_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
