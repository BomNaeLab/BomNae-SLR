{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T10:54:59.024143Z",
     "start_time": "2024-10-05T10:54:58.971646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dir = 'D:/signData'\n",
    "#train_dir = '../data/signData'\n",
    "output_dir = f\"{train_dir}/nptxt\"\n",
    "json_folder_path = f'{train_dir}/train/label/landmark'\n",
    "morpheme_path = f'{train_dir}/train/label/morpheme'\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n"
   ],
   "id": "f294ec67029b0aec",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T11:01:55.055279Z",
     "start_time": "2024-10-05T11:01:51.177992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "person_list=[{\"0\":\"0\"}]\n",
    "person_blacklist=[]\n",
    "for person in os.listdir(json_folder_path):\n",
    "    person_output_path = os.path.join(output_dir, str(int(person)))\n",
    "    os.makedirs(person_output_path, exist_ok=True)\n",
    "    count=1\n",
    "    word_list=[]\n",
    "        \n",
    "\n",
    "    for word_coords,word_morpheme in zip(os.listdir(os.path.join(json_folder_path, person)),os.listdir(os.path.join(morpheme_path, person))):\n",
    "        if \"F\" in word_coords:\n",
    "            wordCoordL = np.empty((0, 4, 5, 3))  \n",
    "            wordCoordR = np.empty((0, 4, 5, 3))\n",
    "            wordCoordP = np.empty((0, 3, 10))\n",
    "            for frame in os.listdir(os.path.join(json_folder_path, person, word_coords)):\n",
    "                file_path = os.path.join(json_folder_path, person, word_coords, frame)\n",
    "                try:\n",
    "                    with open(file_path, 'r') as json_file:\n",
    "                        data = json.load(json_file)\n",
    "                        lh_points = data['people']['hand_left_keypoints_3d']\n",
    "                        rh_points = data['people']['hand_right_keypoints_3d']\n",
    "                        p_points = data['people']['pose_keypoints_3d']\n",
    "\n",
    "                        preFrameCoordP = np.array([[(960 * p_points[i] + 960 - 420) / (1500 - 420), \n",
    "                                                    (1080 * p_points[i + 1] + 540) / 1080,\n",
    "                                                    (p_points[32 + 2] - p_points[i + 2]) / 10]\n",
    "                                                   for i in range(0, len(p_points), 4)], dtype=np.float32)\n",
    "\n",
    "                        preFrameCoordL = np.array([[(960 * lh_points[i] + 960 - 420) / (1500 - 420),\n",
    "                                                    (1080 * lh_points[i + 1] + 540) / 1080,\n",
    "                                                    (lh_points[2] - lh_points[i + 2]) / 10]\n",
    "                                                   for i in range(4, len(lh_points), 4)], dtype=np.float32)\n",
    "\n",
    "                        preFrameCoordR = np.array([[(960 * rh_points[i] + 960 - 420) / (1500 - 420),\n",
    "                                                    (1080 * rh_points[i + 1] + 540) / 1080,\n",
    "                                                    (rh_points[2] - rh_points[i + 2]) / 10]\n",
    "                                                   for i in range(4, len(rh_points), 4)], dtype=np.float32)\n",
    "\n",
    "                        preFrameCoordP = preFrameCoordP[[i for i in range(19) if (0 <= i <= 7) or (17 <= i <= 18)]]\n",
    "\n",
    "                        frameCoordL=preFrameCoordL.reshape(5,4,3).transpose(1,0,2)[::-1]\n",
    "                        frameCoordR=preFrameCoordR.reshape(5,4,3).transpose(1,0,2)[::-1]\n",
    "                        frameCoordP=preFrameCoordP.T\n",
    "                        wordCoordL = np.append(wordCoordL, [frameCoordL], axis=0)\n",
    "                        wordCoordR = np.append(wordCoordR, [frameCoordR], axis=0)\n",
    "                        wordCoordP = np.append(wordCoordP, [frameCoordP], axis=0)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "                    break\n",
    "            if \"F\" in word_morpheme:\n",
    "                file_path = os.path.join(morpheme_path, person, word_morpheme)\n",
    "                morpheme_file_path = os.path.join(morpheme_path, person, word_morpheme)\n",
    "                with open(morpheme_file_path, 'r', encoding=\"UTF8\") as morpheme_file:\n",
    "                    data = json.load(morpheme_file)\n",
    "                    try:\n",
    "                        name = data['data'][0]['attributes'][0]['name']\n",
    "                        # word_list.append({data['metaData']['name'][7:15]:name})\n",
    "                    except IndexError as e:\n",
    "                        person_blacklist.append({person: data['metaData']['name'][7:15]})\n",
    "                        # word_list.append({data['metaData']['name'][7:15]:None})\n",
    "                        print(f\"Error reading {morpheme_file_path}: {e}\")\n",
    "                        continue\n",
    "            label=[count,int(person),name]\n",
    "            word_output_path = os.path.join(person_output_path, f'{label[0]}.npz')\n",
    "            np.savez(word_output_path, wordCoordL=wordCoordL, wordCoordR=wordCoordR, wordCoordP=wordCoordP, label=label)\n",
    "            print(f\"Saved {word_output_path}\")\n",
    "            count+=1\n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "def load_data(person,word):\n",
    "    path=f\"{output_dir}/{person}/{word}.npz\"\n",
    "    data = np.load(path)\n",
    "    wordCoordL = data['wordCoordL']\n",
    "    wordCoordR = data['wordCoordR']\n",
    "    wordCoordP = data['wordCoordP']\n",
    "    label = data['label']\n",
    "\n",
    "    return wordCoordL, wordCoordR, wordCoordP, label\n",
    "\n",
    "\n",
    "def load_word(person, start, num):\n",
    "    words = []\n",
    "    for WNum in range(start, start + num):\n",
    "        wordCoordL, wordCoordR, wordCoordP, label = load_data(person, WNum)\n",
    "        words.append([wordCoordL, wordCoordR, wordCoordP, label])\n",
    "    return words\n",
    "\n",
    "\n",
    "\n",
    "#todo\n",
    "#아래 코드를 함수화 , 포문돌려서 한번에 다 불러오기\n",
    "#함수에 프레임 갯수(영상길이) 호출 가능하게 구현\n",
    "#한 단어 내에서 호출할떄 6개의 프레임씩 겹쳐서 호출 하는 기능 구현\n",
    "\n",
    "\n"
   ],
   "id": "eccd85ceb12e2d01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved D:/signData/nptxt\\1\\1.npz\n",
      "Saved D:/signData/nptxt\\1\\2.npz\n",
      "Saved D:/signData/nptxt\\1\\3.npz\n",
      "Saved D:/signData/nptxt\\1\\4.npz\n",
      "Saved D:/signData/nptxt\\1\\5.npz\n",
      "Saved D:/signData/nptxt\\1\\6.npz\n",
      "Saved D:/signData/nptxt\\1\\7.npz\n",
      "Saved D:/signData/nptxt\\1\\8.npz\n",
      "Saved D:/signData/nptxt\\1\\9.npz\n",
      "Saved D:/signData/nptxt\\1\\10.npz\n",
      "Saved D:/signData/nptxt\\1\\11.npz\n",
      "Saved D:/signData/nptxt\\1\\12.npz\n",
      "Saved D:/signData/nptxt\\1\\13.npz\n",
      "Saved D:/signData/nptxt\\1\\14.npz\n",
      "Saved D:/signData/nptxt\\1\\15.npz\n",
      "Saved D:/signData/nptxt\\1\\16.npz\n",
      "Saved D:/signData/nptxt\\1\\17.npz\n",
      "Saved D:/signData/nptxt\\1\\18.npz\n",
      "Saved D:/signData/nptxt\\1\\19.npz\n",
      "Saved D:/signData/nptxt\\1\\20.npz\n",
      "Saved D:/signData/nptxt\\1\\21.npz\n",
      "Saved D:/signData/nptxt\\1\\22.npz\n",
      "Saved D:/signData/nptxt\\1\\23.npz\n",
      "Saved D:/signData/nptxt\\1\\24.npz\n",
      "Saved D:/signData/nptxt\\1\\25.npz\n",
      "Saved D:/signData/nptxt\\1\\26.npz\n",
      "Saved D:/signData/nptxt\\1\\27.npz\n",
      "Saved D:/signData/nptxt\\1\\28.npz\n",
      "Saved D:/signData/nptxt\\1\\29.npz\n",
      "Saved D:/signData/nptxt\\1\\30.npz\n",
      "Saved D:/signData/nptxt\\1\\31.npz\n",
      "Saved D:/signData/nptxt\\1\\32.npz\n",
      "Saved D:/signData/nptxt\\1\\33.npz\n",
      "Saved D:/signData/nptxt\\1\\34.npz\n",
      "Saved D:/signData/nptxt\\1\\35.npz\n",
      "Saved D:/signData/nptxt\\1\\36.npz\n",
      "Saved D:/signData/nptxt\\1\\37.npz\n",
      "Saved D:/signData/nptxt\\1\\38.npz\n",
      "Saved D:/signData/nptxt\\1\\39.npz\n",
      "Saved D:/signData/nptxt\\1\\40.npz\n",
      "Saved D:/signData/nptxt\\1\\41.npz\n",
      "Saved D:/signData/nptxt\\1\\42.npz\n",
      "Saved D:/signData/nptxt\\1\\43.npz\n",
      "Saved D:/signData/nptxt\\1\\44.npz\n",
      "Saved D:/signData/nptxt\\1\\45.npz\n",
      "Saved D:/signData/nptxt\\1\\46.npz\n",
      "Saved D:/signData/nptxt\\1\\47.npz\n",
      "Saved D:/signData/nptxt\\1\\48.npz\n",
      "Saved D:/signData/nptxt\\1\\49.npz\n",
      "Saved D:/signData/nptxt\\1\\50.npz\n",
      "Saved D:/signData/nptxt\\1\\51.npz\n",
      "Saved D:/signData/nptxt\\1\\52.npz\n",
      "Saved D:/signData/nptxt\\1\\53.npz\n",
      "Saved D:/signData/nptxt\\1\\54.npz\n",
      "Saved D:/signData/nptxt\\1\\55.npz\n",
      "Saved D:/signData/nptxt\\1\\56.npz\n",
      "Saved D:/signData/nptxt\\1\\57.npz\n",
      "Saved D:/signData/nptxt\\1\\58.npz\n",
      "Saved D:/signData/nptxt\\1\\59.npz\n",
      "Saved D:/signData/nptxt\\1\\60.npz\n",
      "Saved D:/signData/nptxt\\1\\61.npz\n",
      "Saved D:/signData/nptxt\\1\\62.npz\n",
      "Saved D:/signData/nptxt\\1\\63.npz\n",
      "Saved D:/signData/nptxt\\1\\64.npz\n",
      "Saved D:/signData/nptxt\\1\\65.npz\n",
      "Saved D:/signData/nptxt\\1\\66.npz\n",
      "Saved D:/signData/nptxt\\1\\67.npz\n",
      "Saved D:/signData/nptxt\\1\\68.npz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 45\u001B[0m\n\u001B[0;32m     43\u001B[0m         frameCoordP\u001B[38;5;241m=\u001B[39mpreFrameCoordP\u001B[38;5;241m.\u001B[39mT\n\u001B[0;32m     44\u001B[0m         wordCoordL \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(wordCoordL, [frameCoordL], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 45\u001B[0m         wordCoordR \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwordCoordR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mframeCoordR\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m         wordCoordP \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(wordCoordP, [frameCoordP], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m json\u001B[38;5;241m.\u001B[39mJSONDecodeError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\Documents\\capstone\\3DCNN_study\\.venv\\Lib\\site-packages\\numpy\\lib\\function_base.py:5618\u001B[0m, in \u001B[0;36mappend\u001B[1;34m(arr, values, axis)\u001B[0m\n\u001B[0;32m   5616\u001B[0m     values \u001B[38;5;241m=\u001B[39m ravel(values)\n\u001B[0;32m   5617\u001B[0m     axis \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mndim\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 5618\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T11:03:56.814876Z",
     "start_time": "2024-10-05T11:03:56.809895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "train_dir = 'D:/signData'\n",
    "#train_dir = '../data/signData'\n",
    "output_dir = f\"{train_dir}/nptxt\"\n",
    "json_folder_path = f'{train_dir}/train/label/landmark'\n",
    "\n",
    "def load_data(person,word):\n",
    "    path=f\"{output_dir}/{person}/{word}.npz\"\n",
    "    data = np.load(path)\n",
    "    wordCoordL = data['wordCoordL']\n",
    "    wordCoordR = data['wordCoordR']\n",
    "    wordCoordP = data['wordCoordP']\n",
    "    label = data['label']\n",
    "\n",
    "    return wordCoordL, wordCoordR, wordCoordP, label\n",
    "\n",
    "\n",
    "def load_word(person, start, num):\n",
    "    words = []\n",
    "    count = 0\n",
    "    for WNum in range(start, start + num):\n",
    "        wordCoordL, wordCoordR, wordCoordP, label = load_data(person, WNum)\n",
    "        words.append([wordCoordL, wordCoordR, wordCoordP, label])\n",
    "        count += 1\n",
    "    return words, count\n",
    "\n",
    "\n",
    "test_data, count = load_word(1, 1, 1)\n",
    "print(test_data[0][3])\n",
    "\n"
   ],
   "id": "40befbcce19deeaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '1' '고민']\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "count = 0\n",
    "person_list = {}  # 딕셔너리로 수정\n",
    "person_blacklist = []\n",
    "\n",
    "# for person in os.listdir(json_folder_path):\n",
    "#     count = 0\n",
    "\n",
    "print(len(person_list))\n",
    "print(person_blacklist)\n"
   ],
   "id": "2c9d2908455754c1"
  },
  {
   "cell_type": "code",
   "id": "04ea544c",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
