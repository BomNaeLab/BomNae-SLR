{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SLR_model_CL_GRU\n",
    "import SLR_model_GRU\n",
    "import importlib\n",
    "import time\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.math import top_k\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "prediction = tf.random.uniform((3000,))\n",
    "\n",
    "res = top_k(prediction, k=2)\n",
    "res_np = res.values.numpy()\n",
    "res.indices.numpy()\n",
    "confidence_multiplier = res_np[0] - res_np[1]\n",
    "vote_wdw_size = 5\n",
    "\n",
    "# queue that stores (idx, conf) pair\n",
    "# if queue size > window_size:\n",
    "#   pop queue\n",
    "# append queue\n",
    "\n",
    "## weighted vote using queue, generate a list with (idx, conf_sum) or separate lists containing each\n",
    "# for elem queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d11be8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "\n",
    "l_raw, r_raw, p_raw, y_raw, loss_weights_raw = preprocess.load_data(f\"1/1\")\n",
    "# l_raws.append(l_raw)\n",
    "# r_raws.append(r_raw)\n",
    "# p_raws.append(p_raw)\n",
    "# y_raws.append(y_raw)\n",
    "# loss_weights_raws.append(loss_weights_raw)\n",
    "\n",
    "# if len(l_raws)>=load_size:\n",
    "# l_train, each = SLR_model.serialize((l_raw,))\n",
    "# r_train, each = SLR_model.serialize((r_raws,))\n",
    "p_train, each, sample_weights = SLR_model.serialize((p_raw,), stride=2, loss_weights_list=(loss_weights_raw,))\n",
    "# x_train = (l_train, r_train, p_train)\n",
    "\n",
    "y_train = np.repeat((y_raw,), each)\n",
    "# y_train = SLR_model.encode_onehot2d(y_train)\n",
    "\n",
    "\n",
    "print(y_train)\n",
    "x = np.linspace(0,len(sample_weights), len(sample_weights))\n",
    "\n",
    "plt.plot(x, sample_weights)\n",
    "\n",
    "# dataset = SLR_model.convert_to_dataset(x_train, y_train, batch_size, sample_weights)\n",
    "# hist = model.fit(dataset, epochs=epochs, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad8327d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2897833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per video dummy data\n",
    "# dummy x_raw data\n",
    "\n",
    "h_elem = np.zeros(shape=(4,5,3))\n",
    "l_raw = []\n",
    "duration = np.random.randint(70,111)\n",
    "for j in range(duration): # frame size\n",
    "    l_raw.append(h_elem)\n",
    "h_elem = np.zeros(shape=(4,5,3))\n",
    "r_raw = []\n",
    "for j in range(duration): # frame size\n",
    "    r_raw.append(h_elem)\n",
    "\n",
    "p_elem = np.zeros(shape=(3,10))\n",
    "p_raw = []\n",
    "for j in range(duration): # frame size\n",
    "    p_raw.append(p_elem)\n",
    "\n",
    "\n",
    "loss_weights_raw = []\n",
    "\n",
    "for j in range(duration+1): # frame size\n",
    "    loss_weights_raw.append(1.0)\n",
    "\n",
    "y_raw = np.array(2048, dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d04a1b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timecallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        # use this value as reference to calculate cummulative time taken\n",
    "        self.timetaken = time.process_time()\n",
    "    def on_epoch_end(self,epoch,logs = {}):\n",
    "        \n",
    "        self.times.append((epoch,time.process_time() - self.timetaken))\n",
    "        print(time.process_time() - self.timetaken)\n",
    "        self.timetaken = time.process_time()\n",
    "    def on_train_end(self,logs = {}):\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Total time taken until an epoch in seconds')\n",
    "        plt.plot(*zip(*self.times))\n",
    "        plt.show()\n",
    "        \n",
    "timetaken = timecallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bd6fb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'SLR_model_CL_GRU' from 'c:\\\\Users\\\\jerry\\\\Desktop\\\\hly\\\\2024-2\\\\cap\\\\BN_SLR\\\\BomNae-SLR-1\\\\SLR_model_CL_GRU.py'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(SLR_model_CL_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c30e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\SpecialPrograms\\Anaconda3\\envs\\slr\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SLR_model_CL_GRU.reinit_model(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebaee526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SpecialPrograms\\Anaconda3\\envs\\slr\\lib\\site-packages\\keras\\src\\layers\\layer.py:391: UserWarning: `build()` was called on layer 'slr_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - categorical_accuracy: 0.0000e+00 - loss: 8.0064\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - categorical_accuracy: 1.0000 - loss: 7.8411\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - categorical_accuracy: 1.0000 - loss: 5.1736\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - categorical_accuracy: 1.0000 - loss: 2.6285\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - categorical_accuracy: 1.0000 - loss: 2.4247\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - categorical_accuracy: 1.0000 - loss: 2.2237\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - categorical_accuracy: 1.0000 - loss: 2.0212\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - categorical_accuracy: 1.0000 - loss: 1.8195\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - categorical_accuracy: 1.0000 - loss: 1.6220\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - categorical_accuracy: 1.0000 - loss: 1.4311\n"
     ]
    }
   ],
   "source": [
    "# PER VIDEO TRAINING LOOP\n",
    "\n",
    "## ----------------------------------------------------\n",
    "## CLGRU <-> CNNGRU 전환시 serialize 인자값 바꿔줄 것\n",
    "## --------------------------------------\n",
    "l_train, window_count = SLR_model_CL_GRU.serialize(l_raw, stride=2, window_size=9, hop_length=6)\n",
    "r_train, window_count = SLR_model_CL_GRU.serialize(r_raw, stride=2, window_size=9, hop_length=6)\n",
    "p_train, window_count, sample_weights = SLR_model_CL_GRU.serialize(p_raw, stride=2, window_size=9, hop_length=6, loss_weights=loss_weights_raw, is_pose=True)\n",
    "x_train = (l_train, r_train, p_train)\n",
    "\n",
    "y_train = np.repeat(y_raw, window_count)\n",
    "y_train = SLR_model_CL_GRU.encode_onehot2d(y_raw)\n",
    "y_train = tf.expand_dims(y_train, axis=0)\n",
    "# print(y_train.shape)\n",
    "# print(x_train[0].shape)\n",
    "# print(x_train[1].shape)\n",
    "# print(x_train[2].shape)\n",
    "# print(sample_weights.shape)\n",
    "dataset = SLR_model_CL_GRU.convert_to_dataset(x_train, y_train, batch_size= 1)#, sample_weights= sample_weights)\n",
    "hist = model.fit(dataset, epochs=10)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6bc88f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, stat = model(x_train, training=False, gru_state = stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "792c4b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([2048], dtype=int64)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SLR_model_CL_GRU.decode_onehot2d(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0165c385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
       "array([[-1.        , -1.        ,  0.9999969 ,  1.        , -0.9999999 ,\n",
       "         1.        ,  1.        ,  0.9999986 ,  1.        , -1.        ,\n",
       "        -1.        , -0.19753836, -1.        , -0.99997187,  0.9999967 ,\n",
       "         1.        ,  1.        , -1.        ,  1.        , -1.        ,\n",
       "        -1.        ,  1.        , -1.        , -1.        ,  0.99999994,\n",
       "        -1.        ,  1.        , -1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.9644135 , -1.        , -1.        , -1.        ,\n",
       "         0.9996992 , -1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        -0.99999994, -0.9999989 , -1.        ,  1.        , -1.        ,\n",
       "         1.        , -1.        , -1.        , -1.        ,  0.9999988 ,\n",
       "        -1.        ,  1.        ,  1.        , -1.        , -1.        ,\n",
       "         0.9999998 ,  1.        , -1.        ,  1.        ,  0.99999994,\n",
       "        -0.9999999 ,  1.        , -1.        , -1.        ,  1.        ,\n",
       "        -0.99999964, -1.        , -0.99999917,  1.        , -1.        ,\n",
       "        -1.        ,  1.        , -1.        , -0.99999994,  0.9999981 ,\n",
       "         1.        ,  0.9999998 , -1.        ,  1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ,  1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.99999994,  1.        , -1.        , -1.        , -1.        ,\n",
       "         0.99999994, -1.        , -0.9999994 ,  1.        , -0.999995  ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        -1.        ,  0.9999997 , -1.        , -0.99999976, -1.        ,\n",
       "         1.        , -0.9999995 , -0.953     , -1.        ,  1.        ,\n",
       "         0.99999994,  1.        , -1.        ,  0.9999997 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.9999994 , -0.99999976,\n",
       "        -1.        , -1.        ,  1.        , -1.        , -0.9999998 ,\n",
       "         1.        , -1.        ,  1.        , -0.9999997 ,  1.        ,\n",
       "        -0.99999887,  0.9999999 ,  0.99997306,  1.        ,  0.99997   ,\n",
       "         0.99999994, -1.        , -1.        , -1.        ,  1.        ,\n",
       "        -1.        ,  0.99999934, -1.        ,  1.        ,  1.        ,\n",
       "         0.99995714, -0.98905385, -1.        , -1.        , -1.        ,\n",
       "        -0.999988  , -1.        , -1.        ,  1.        ,  0.00619967,\n",
       "         0.81276524, -1.        , -0.44169652,  0.9999997 , -1.        ,\n",
       "        -1.        , -1.        , -1.        ,  1.        , -1.        ,\n",
       "        -1.        ,  1.        , -1.        , -1.        ,  0.22798035,\n",
       "        -0.9030747 ,  0.99999994, -1.        ,  1.        , -0.9999931 ,\n",
       "         0.99999994, -1.        , -0.5566916 ,  1.        , -0.9998416 ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.9999997 ,  1.        ,  0.99999374,\n",
       "        -1.        ,  1.        , -1.        ,  1.        , -1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        -0.99999994,  1.        , -1.        , -0.99992484,  0.99999994,\n",
       "         1.        ,  0.9826623 ,  0.9999995 ,  1.        , -1.        ,\n",
       "        -1.        , -0.99999994, -0.9999999 , -1.        ,  0.99999595,\n",
       "         1.        , -0.9997097 , -0.9999999 ,  1.        , -1.        ,\n",
       "        -1.        , -1.        ,  1.        , -1.        ,  1.        ,\n",
       "        -1.        ,  1.        , -0.9999993 , -1.        ,  1.        ,\n",
       "         1.        ,  1.        , -1.        , -0.9999971 ,  1.        ,\n",
       "         0.5620403 ,  1.        , -0.8613044 , -1.        ,  0.96195894,\n",
       "        -1.        ,  1.        , -0.9999999 ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        , -0.27940655,  1.        , -0.9998951 ,\n",
       "         1.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086de540",
   "metadata": {},
   "source": [
    "---------------\n",
    "# CNN GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2fc89a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'SLR_model_GRU' from 'c:\\\\Users\\\\jerry\\\\Desktop\\\\hly\\\\2024-2\\\\cap\\\\BN_SLR\\\\BomNae-SLR-1\\\\SLR_model_GRU.py'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(SLR_model_GRU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbca44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cngru_model = SLR_model_GRU.reinit_model(run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "893153b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 6/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 7/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 8/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 9/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 10/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 11/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 12/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 13/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 14/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 15/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 16/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 17/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 18/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 19/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 20/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 21/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 22/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 23/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 24/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 25/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 26/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 27/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 28/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 29/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 30/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - categorical_accuracy: 1.0000 - loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# PER VIDEO TRAINING LOOP\n",
    "\n",
    "## ----------------------------------------------------\n",
    "## CLGRU <-> CNNGRU 전환시 serialize 인자값 바꿔줄 것\n",
    "## --------------------------------------\n",
    "l_train, window_count = SLR_model_GRU.serialize(l_raw, stride=1, window_size=17, hop_length=10)\n",
    "r_train, window_count = SLR_model_GRU.serialize(r_raw, stride=1, window_size=17, hop_length=10)\n",
    "p_train, window_count, sample_weights = SLR_model_GRU.serialize(p_raw, stride=2, window_size=9, hop_length=6, loss_weights=loss_weights_raw, is_pose=True)\n",
    "x_train = (l_train, r_train, p_train)\n",
    "\n",
    "y_train = np.repeat(y_raw, window_count)\n",
    "y_train = SLR_model_GRU.encode_onehot2d(y_raw)\n",
    "y_train = tf.expand_dims(y_train, axis=0)\n",
    "# print(y_train.shape)\n",
    "# print(\"li:\",x_train[0].shape)\n",
    "# print(\"ri:\",x_train[1].shape)\n",
    "# print(x_train[2].shape)\n",
    "# print(sample_weights.shape)\n",
    "dataset = SLR_model_GRU.convert_to_dataset(x_train, y_train, batch_size= 1)#, sample_weights= sample_weights)\n",
    "hist = cngru_model.fit(dataset, epochs=30)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a2b8266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"slr_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"slr_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hand_model (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">HandModel</span>)          │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">151,776</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hand_model_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">HandModel</span>)        │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">151,776</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pose_model (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PoseModel</span>)          │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,323,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3000</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">771,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1020</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Project</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,547,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ project_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Project</span>)             │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">58,752</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hand_model (\u001b[38;5;33mHandModel\u001b[0m)          │ ?                      │       \u001b[38;5;34m151,776\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hand_model_1 (\u001b[38;5;33mHandModel\u001b[0m)        │ ?                      │       \u001b[38;5;34m151,776\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pose_model (\u001b[38;5;33mPoseModel\u001b[0m)          │ ?                      │        \u001b[38;5;34m23,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │    \u001b[38;5;34m10,323,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3000\u001b[0m)              │       \u001b[38;5;34m771,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1020\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ project (\u001b[38;5;33mProject\u001b[0m)               │ ?                      │     \u001b[38;5;34m6,547,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ project_1 (\u001b[38;5;33mProject\u001b[0m)             │ ?                      │        \u001b[38;5;34m58,752\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,083,162</span> (206.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,083,162\u001b[0m (206.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,027,720</span> (68.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,027,720\u001b[0m (68.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,055,442</span> (137.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m36,055,442\u001b[0m (137.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cngru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f46e9594",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    pred= cngru_model(x_train, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4932d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([2048], dtype=int64)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SLR_model_GRU.decode_onehot2d(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1972fd1",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5cc781f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m l_raws \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m duration_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mload_size\u001b[49m):\n\u001b[0;32m      5\u001b[0m     h_elem \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# p_elem = np.zeros(shape=(3,10))\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# comb_elem = [h_elem, h_elem, p_elem]\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_size' is not defined"
     ]
    }
   ],
   "source": [
    "# dummy x_raw data\n",
    "l_raws = []\n",
    "duration_list = []\n",
    "for i in range(load_size):\n",
    "    h_elem = np.zeros(shape=(4,5,3))\n",
    "    # p_elem = np.zeros(shape=(3,10))\n",
    "    # comb_elem = [h_elem, h_elem, p_elem]\n",
    "    x_elem = []\n",
    "    duration = (np.random.randint(70,91))\n",
    "    duration_list.append(duration)\n",
    "    for j in range(duration): # frame size\n",
    "        x_elem.append(h_elem)\n",
    "        # x_elem.append(comb_elem)\n",
    "    l_raws.append(x_elem)\n",
    "r_raws = []\n",
    "for i in range(load_size):\n",
    "    h_elem = np.zeros(shape=(4,5,3))\n",
    "    # p_elem = np.zeros(shape=(3,10))\n",
    "    # comb_elem = [h_elem, h_elem, p_elem]\n",
    "    x_elem = []\n",
    "    duration = duration_list[i]\n",
    "    for j in range(duration): # frame size\n",
    "        x_elem.append(h_elem)\n",
    "        # x_elem.append(comb_elem)\n",
    "    r_raws.append(x_elem)\n",
    "p_raws = []\n",
    "for i in range(load_size):\n",
    "    # h_elem = np.zeros(shape=(4,5,3))\n",
    "    p_elem = np.zeros(shape=(3,10))\n",
    "    # comb_elem = [h_elem, h_elem, p_elem]\n",
    "    x_elem = []\n",
    "    duration = duration_list[i]\n",
    "    for j in range(duration): # frame size\n",
    "        # x_elem.append(h_elem)\n",
    "        x_elem.append(p_elem)\n",
    "        # x_elem.append(comb_elem)\n",
    "    p_raws.append(x_elem)\n",
    "    \n",
    "loss_weights_raws = []\n",
    "for i in range(load_size):\n",
    "    x_elem = []\n",
    "    duration = duration_list[i]\n",
    "    for j in range(duration): # frame size\n",
    "        x_elem.append(2.0)\n",
    "    loss_weights_raws.append(x_elem)\n",
    "\n",
    "# dummy y_raw data\n",
    "# y_raw = np.random.randint(0,1024,load_size)\n",
    "y_raws = np.full((load_size,), 2048,  dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f3e1d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'SLR_model' from 'c:\\\\Users\\\\jerry\\\\Desktop\\\\hly\\\\2024-2\\\\cap\\\\BN_SLR\\\\BomNae-SLR-1\\\\SLR_model.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(SLR_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c1b560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oh = SLR_model.encode_onehot2d([0,0,3,7,6,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa748a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3000), dtype=float32, numpy=\n",
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67fec035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int64, numpy=array([0, 0, 3, 7, 6, 2], dtype=int64)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SLR_model.decode_onehot2d(oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aa5a8b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_raws' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my_raws\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_raws' is not defined"
     ]
    }
   ],
   "source": [
    "y_raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3c528c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "lw_S: 99\n",
      "yt_S: (99, 12)\n",
      "xt[0]_S: (99, 63, 4, 5, 3)\n",
      "(8, 12)\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - binary_accuracy: 0.8074 - loss: 1.3836\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "# model = SLR_model.reinit_model(True)\n",
    "model = SLR_model.get_model()\n",
    "\n",
    "l_train, each = SLR_model.serialize(l_raws)\n",
    "r_train, each = SLR_model.serialize(r_raws)\n",
    "print(len(p_raws), len(loss_weights_raws))\n",
    "p_train, each, sample_weights = SLR_model.serialize(p_raws, stride=2, loss_weights_list=loss_weights_raws)\n",
    "y_train_truth = np.repeat(y_raws, each)\n",
    "y_train_truth1 = SLR_model.num_arr2bin(y_train_truth, 12)\n",
    "# check\n",
    "\n",
    "print(\"lw_S:\", len(sample_weights))\n",
    "print(\"yt_S:\", y_train_truth1.shape)\n",
    "\n",
    "# y_train = tf.concat((y_train_truth1, loss_weights), axis = 1)\n",
    "\n",
    "# y_train = tf.zeros(shape=(113,6,12))\n",
    "x_train = (l_train, r_train, p_train)\n",
    "\n",
    "print(\"xt[0]_S:\", x_train[0].shape)\n",
    "# print(\"y_train shape: (\", y_train[0].shape,', ', len(y_train[1]), ')')\n",
    "dataset = SLR_model.convert_to_dataset(x_train, y_train_truth1, batch_size, sample_weights)\n",
    "for i in dataset:\n",
    "    print(i[1].shape)\n",
    "    break\n",
    "hist = model.fit(dataset, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cd130e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = tf.zeros(shape = (3,12), dtype= tf.float32)\n",
    "ab = tf.ones(shape = (3,1),dtype= tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7befcf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.concat((aa, ab), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "96fbf573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "37b9236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,:12].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "683196e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dadc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4fc99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18300b6e",
   "metadata": {},
   "source": [
    "---\n",
    "**keras layer test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0ce9f1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([18, 32, 3, 3])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(32, 3, 10), batch_size=18)\n",
    "# frame channel feat\n",
    "d2 = layers.Dense(3, activation='relu')\n",
    "outputs = layers.TimeDistributed(d2)(inputs)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "630e52eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([18, 3, 32, 3, 1])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = layers.Permute((2, 1, 3))(outputs)\n",
    "outputs = tf.expand_dims(outputs, axis=4)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "72c2ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = tf.split(outputs, 3, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "50248481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(18, 1, 32, 3, 1) dtype=float32 (created by layer 'tf.split_3')>,\n",
       " <KerasTensor: shape=(18, 1, 32, 3, 1) dtype=float32 (created by layer 'tf.split_3')>,\n",
       " <KerasTensor: shape=(18, 1, 32, 3, 1) dtype=float32 (created by layer 'tf.split_3')>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b0b57ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([18, 1, 16, 1, 1])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 = layers.Conv2D(1, (17,3))\n",
    "x = c2(xyz[0])\n",
    "y = c2(xyz[1])\n",
    "z = c2(xyz[2])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0db9f99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([18, 16])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.squeeze(x)\n",
    "y = tf.squeeze(y)\n",
    "z = tf.squeeze(z)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "401ccee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([18, 16, 3])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = tf.stack([x,y,z], axis=2)\n",
    "# o = tf.concat([x,y,z], axis = 0)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26bbd566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(32, 3, 16, 2) dtype=float32 (created by layer 'tf.compat.v1.squeeze_3')>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58655265",
   "metadata": {},
   "source": [
    "- hand model layer test -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fc5ba74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 16, 2, 3, 1])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(63, 4, 5, 3), batch_size=32)\n",
    "# frame, w, h, channel\n",
    "c21d = Conv2Plus1D(kernel_size=(33,3,3), strides=(2, 1, 1))\n",
    "outputs = c21d(inputs)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a416794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 96])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2 = layers.Flatten()(outputs)\n",
    "o2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7704b34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 16, 6])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2 = outputs\n",
    "o2 = layers.Reshape((16, o2.shape[2] * o2.shape[3]* o2.shape[4]))(o2)\n",
    "o2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451beb40",
   "metadata": {},
   "source": [
    "- combined layer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2bc944cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 240])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_res = layers.Input(shape=(16, 6), batch_size=32)\n",
    "r_res = layers.Input(shape=(16, 6), batch_size=32)\n",
    "p_res = layers.Input(shape=(16, 3), batch_size=32)\n",
    "fl = layers.Flatten()\n",
    "lflt =fl(l_res)\n",
    "rflt = fl(r_res)\n",
    "pflt = fl(p_res)\n",
    "ult_flat = tf.concat([lflt, rflt, pflt], axis = 1)\n",
    "ult_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39bd82",
   "metadata": {},
   "source": [
    "**layer test**\n",
    "\n",
    "---\n",
    "\n",
    "**other experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b515109c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1,  0.2,  0.3,  0.4],\n",
       "       [ 1. ,  2. ,  3. ,  4. ],\n",
       "       [11. , 22. , 33. , 44. ]], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf = tf.constant(([0.1, 0.2, 0.3, 0.4],[1, 2, 3, 4], [11,22,33,44]))\n",
    "# asdf = tf.expand_dims(asdf, axis=0)\n",
    "\n",
    "asdf.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287d0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "212c4425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 4])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ashpe = asdf.shape\n",
    "ashpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d6bf2af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 4])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf = tf.reshape(asdf, (1,12))\n",
    "ashpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "de4f2bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.1, 0.2, 0.3, 0.4]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[1., 2., 3., 4.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[11., 22., 33., 44.]], dtype=float32)>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ababs = tf.split(asdf, 3)\n",
    "ababs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aa34930a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(1, 4, 3), dtype=float32, numpy=\n",
       "array([[[ 0.1,  1. , 11. ],\n",
       "        [ 0.2,  2. , 22. ],\n",
       "        [ 0.3,  3. , 33. ],\n",
       "        [ 0.4,  4. , 44. ]]], dtype=float32)>>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abab = tf.stack([ababs[0],ababs[1],ababs[2]], axis=2)\n",
    "abab.numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "003f29e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 0.1,  1. , 10. ],\n",
       "       [ 0.2,  2. , 20. ],\n",
       "       [ 0.3,  3. , 30. ]], dtype=float32)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(asdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "93050123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n",
      "0\n",
      "[1. 1.]\n",
      "1\n",
      "[1. 1.]\n",
      "2\n",
      "[1. 1.]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i,val in enumerate(asdf):\n",
    "    print(val.numpy())\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9316a217",
   "metadata": {},
   "source": [
    "---\n",
    "**Multi input test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73afe2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiInputModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MultiInputModel, self).__init__()\n",
    "        \n",
    "        # Define layers for input 1\n",
    "        self.dense1 = tf.keras.layers.Dense(2, activation='relu')\n",
    "        \n",
    "        # Define layers for input 2\n",
    "        self.dense3 = tf.keras.layers.Dense(3, activation='relu')\n",
    "\n",
    "        \n",
    "        # Common layers for both inputs\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.dense_final = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Unpack inputs\n",
    "        input1, input2 = inputs\n",
    "        \n",
    "        # Process input 1\n",
    "        x1 = self.dense1(input1)\n",
    "        \n",
    "        # Process input 2\n",
    "        x2 = self.dense3(input2)\n",
    "        \n",
    "        # Concatenate the processed inputs\n",
    "        x = self.concat([x1, x2])\n",
    "        \n",
    "        # Final dense layer\n",
    "        output = self.dense_final(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78211972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multi_input_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             multiple                  18        \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  15        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " concatenate_2 (Concatenate)  multiple                 0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39\n",
      "Trainable params: 39\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Output shape: (32, 1)\n"
     ]
    }
   ],
   "source": [
    "model = MultiInputModel()\n",
    "\n",
    "# Dummy inputs for demonstration (e.g., two inputs with 8 features each)\n",
    "input1 = np.ones((32, 8))  # Batch size 32, 8 features\n",
    "input2 = np.zeros((32, 4))  # Batch size 32, 8 features\n",
    "# input2 = tf.random.normal((32, 4))  # Batch size 32, 8 features\n",
    "\n",
    "# Forward pass\n",
    "output = model([input1, input2])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Print the output shape\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0820754a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424],\n",
       "       [0.8391424]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([input1, input2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
