{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464274c8",
   "metadata": {},
   "source": [
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "##  THIS IS A TRAINING MODEL, IMPLEMENTION DETAIL MAY DIFFER FROM PRODUCTION MODEL  ##\n",
    "#------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "# THIS IS AN ABSTRACT BACKBONE SCRIPT, ACTUAL IMPLEMENTATION WILL BE IN .PY FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d3eafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "model = None\n",
    "he_init = initializers.HeUniformV2()\n",
    "\n",
    "# Hyperparamerters\n",
    "# hand : conv3D\n",
    "hand_filter_size = 1\n",
    "hand_kernel_size = (33, 3, 3)\n",
    "hand_stride = (2,1,1)\n",
    "# pose: conv2D\n",
    "pose_filter_size = 1\n",
    "pose_dense_size = 3\n",
    "pose_kernel_size = (17,3)\n",
    "pose_stride = (1,1)\n",
    "# combined FC\n",
    "combined_dense1_size = 256\n",
    "combined_dense2_size = 128\n",
    "combined_output_size = 12\n",
    "# optimizer\n",
    "learning_rate = 0.0001\n",
    "loss = 'mse'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec35377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom layer definition\n",
    "class Conv2Plus1D(layers.Layer):\n",
    "    def __init__(self, kernel_size, filters = 1, strides = (1,1,1), padding = 'valid'):\n",
    "        \"\"\"kernel_size is depth width height\"\"\"\n",
    "        super().__init__()\n",
    "        wh_stride = (1, strides[1], strides[2])\n",
    "        t_stride = (strides[0], 1, 1)\n",
    "        self.seq = keras.Sequential([  \n",
    "        # Spatial decomposition\n",
    "        layers.Conv3D(filters=filters,\n",
    "                      kernel_size=(1, kernel_size[1], kernel_size[2]), strides = wh_stride,\n",
    "                      padding=padding),\n",
    "        # Temporal decomposition\n",
    "        layers.Conv3D(filters=filters, \n",
    "                      kernel_size=(kernel_size[0], 1, 1), strides = t_stride,\n",
    "                      padding=padding)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "376af06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand model\n",
    "class HandModel(Model):\n",
    "    # run it every 2 frames in order to give it 2 temporal stride\n",
    "    \"\"\"input shape: (batch, time, h, w, channels)\n",
    "        output shape: (batch, convolved_time, convolved_h * convolved_w * filter_size)\"\"\"\n",
    "    def __init__(self, kernel_size = (33,3,3), filters= 1, strides = (2,1,1)):\n",
    "        super().__init__()\n",
    "        self.conv21 = Conv2Plus1D(kernel_size = kernel_size, filters= filters, strides = strides)\n",
    "        self.ln = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x, training= False):\n",
    "        x = self.conv21(x)\n",
    "        conv_shape = x.shape\n",
    "        # current shape: (batch, convolved_time, convolved_h, convolved_w, filter_size)\n",
    "        x = tf.squeeze(x)\n",
    "        x = layers.Reshape((conv_shape[1], conv_shape[2] * conv_shape[3] * conv_shape[4]))(x)\n",
    "        return self.ln(x, training= training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df2e3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose model\n",
    "\n",
    "\n",
    "class PoseModel(Model):\n",
    "    \"\"\"input shape: (batch, time, channel, features)\\n\n",
    "        output shape: (batch, convolved_time, xyz_channel * filter_size)\"\"\"\n",
    "    def __init__(self, kernel_size = (17,3), filters = 1, dense_size = 3):\n",
    "        super().__init__()\n",
    "        self.dense_size = dense_size\n",
    "        self.dense_td = layers.TimeDistributed(layers.Dense(dense_size, activation='relu', kernel_initializer= he_init))\n",
    "        self.conv2_x = layers.Conv2D(filters=filters, kernel_size = kernel_size)\n",
    "        self.conv2_y = layers.Conv2D(filters=filters, kernel_size = kernel_size)\n",
    "        self.conv2_z = layers.Conv2D(filters=filters, kernel_size = kernel_size)\n",
    "        self.ln = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, input, training= False):\n",
    "        # input shape:  batch time channel features\n",
    "        # output shape: batch channel conv_result\n",
    "        temp = self.dense_td(input, training = training)\n",
    "        # time channel FC_result -> channel time FC_result\n",
    "        temp = layers.Permute((2, 1, 3))(temp)\n",
    "        # below force adds required \"channel\" input for 2dCNN (not to confuse with xyz channel)\n",
    "        temp = tf.expand_dims(temp, axis=4)\n",
    "        # current shape: xyz_channel, time, FC_result, 1\n",
    "        xyz = tf.split(temp, 3, axis = 1)\n",
    "        x = self.conv2_x(xyz[0])\n",
    "        y = self.conv2_y(xyz[1])\n",
    "        z = self.conv2_z(xyz[2])\n",
    "        conv_shape = x.shape\n",
    "        # shape: (batch, 1, conv_time, 1, filter_size) -> (batch, conv_time, filter_size) -> (batch, conv_time, xyz_ch, filter_size)\n",
    "        x = tf.squeeze(x)\n",
    "        y = tf.squeeze(y)\n",
    "        z = tf.squeeze(z)\n",
    "        temp = tf.stack([x, y, z], axis=2)\n",
    "        temp = layers.Reshape((conv_shape[2], 3 * conv_shape[4])) # 3 from x y z 3 channels\n",
    "        return self.ln(temp, training = training)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c48691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main model class\n",
    "class SLRModel(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.left_hand_model = HandModel(kernel_size = hand_kernel_size, filters = hand_filter_size, strides=hand_stride)\n",
    "        self.right_hand_model = HandModel(kernel_size = hand_kernel_size, filters = hand_filter_size, strides=hand_stride)\n",
    "        self.pose_model = PoseModel(kernel_size = pose_kernel_size, filters=pose_filter_size, dense_size = pose_dense_size)\n",
    "        self.dense1 = layers.Dense(combined_dense1_size, activation='gelu', kernel_initializer = he_init)\n",
    "        self.dense2 = layers.Dense(combined_dense2_size, activation='gelu', kernel_initializer = he_init)\n",
    "        # TODO 4096 max, check EXACT data size\n",
    "        self.dense_out = layers.Dense(combined_output_size, activation='sigmoid')\n",
    "        self.flat = layers.Flatten()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs 0: L, 1: R, 2: Pose\n",
    "        l_res = self.left_hand_model(inputs[0])\n",
    "        r_res = self.right_hand_model(inputs[1])\n",
    "        p_res = self.pose_model(inputs[2])\n",
    "        l_res = self.flat(l_res)\n",
    "        r_res = self.flat(r_res)\n",
    "        p_res = self.flat(p_res)\n",
    "        x = tf.concat([l_res, r_res, p_res], axis = 1)\n",
    "        # current_shape: (batch, hand_output_size * 2 + pose_output_size)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense_out(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca067168",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SLRModel()\n",
    "optimizer = optimizers.Adam(learning_rate = learning_rate)\n",
    "# model.build((1,))\n",
    "model.compile(optimizer = optimizer, loss=loss, run_eagerly=False)\n",
    "\n",
    "# def get_model():\n",
    "#     return model\n",
    "\n",
    "# def model_summary():\n",
    "#     return model.summary()\n",
    "\n",
    "def set_batch_size(size = 16):\n",
    "    global batch_size\n",
    "    batch_size = size\n",
    "\n",
    "def train(x_train, y_train, epochs):\n",
    "    hist = model.fit(x_train, y_train, epochs = epochs, batch_size= batch_size)\n",
    "    return hist\n",
    "\n",
    "def predict(inputs, verbose='auto'):\n",
    "    res = model.predict(inputs, verbose= verbose)\n",
    "    return res\n",
    "\n",
    "# the part that doesnt get executed when imported\n",
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f4bcddb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15484\\3470139634.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jerry\\.conda\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3291\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3292\u001b[0m             raise ValueError(\n\u001b[1;32m-> 3293\u001b[1;33m                 \u001b[1;34m\"This model has not yet been built. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3294\u001b[0m                 \u001b[1;34m\"Build the model first by calling `build()` or by calling \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3295\u001b[0m                 \u001b[1;34m\"the model on a batch of data.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab19d2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
